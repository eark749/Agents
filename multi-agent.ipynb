{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b1add0",
   "metadata": {},
   "source": [
    "# Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881765f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4343e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gpt-3.5-turbo'}\n"
     ]
    }
   ],
   "source": [
    "print(llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7183f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68aa6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[autogen.oai.client: 12-04 17:26:02] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent = ConversableAgent(name=\"chatbot\", llm_config=llm_config, human_input_mode=\"NEVER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184eca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you:\n",
      "\n",
      "Why couldn't the bicycle find its way home? Because it lost its bearings!\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "        messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    "    )\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e8d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Which joke would you like me to repeat for you?\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a909f",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "815447c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[autogen.oai.client: 12-04 17:31:04] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\u001b[0m\n",
      "\u001b[33m[autogen.oai.client: 12-04 17:31:04] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b56219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Thanks, Cathy! That scarecrow must really be branching out in his career!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, looks like he's really growing in popularity! Hope he doesn't let it all go to his head!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69b23d",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49098e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Hey Joe! Why did the scarecrow win an award? Because he was '\n",
      "             'outstanding in his field!',\n",
      "  'role': 'user'},\n",
      " {'content': 'Thanks, Cathy! That scarecrow must really be branching out in '\n",
      "             'his career!',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Haha, looks like he's really growing in popularity! Hope he \"\n",
      "             \"doesn't let it all go to his head!\",\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3f842d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 60,\n",
      "                                                             'cost': 0.00018450000000000004,\n",
      "                                                             'prompt_tokens': 189,\n",
      "                                                             'total_tokens': 249},\n",
      "                                      'total_cost': 0.00018450000000000004},\n",
      " 'usage_including_cached_inference': {'gpt-3.5-turbo-0125': {'completion_tokens': 60,\n",
      "                                                             'cost': 0.00018450000000000004,\n",
      "                                                             'prompt_tokens': 189,\n",
      "                                                             'total_tokens': 249},\n",
      "                                      'total_cost': 0.00018450000000000004}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33732d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Haha, looks like he's really growing in popularity! Hope he doesn't let it \"\n",
      " 'all go to his head!')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371af273",
   "metadata": {},
   "source": [
    "# chat termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "966d5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[autogen.oai.client: 12-04 17:34:27] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\u001b[0m\n",
      "\u001b[33m[autogen.oai.client: 12-04 17:34:27] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac687812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Why did the golfer bring two pairs of pants? In case he got a hole in one!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, classic! I guess he was prepared for any \"fore\" seeable accidents!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, exactly! Sounds like he was really putting his best foot forward!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Absolutely, couldn't afford to get \"caught in the rough\" with just one pair!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "That's right, Joe! He was ready to \"putt\" on a good show no matter what!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, he definitely had a \"tee-rific\" sense of humor about it!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, looks like he was \"driver\"-en to keep the laughs going!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "He was definitely \"wedge\"ing his way into comedy gold with those extra pants!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, sounds like he was really \"iron\" out those comedic details!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "He was on a \"par\" with his jokes for sure! Okay, I gotta go. It was fun chatting with you, Cathy!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89fd6397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "The last joke we talked about was about the golfer bringing two pairs of pants in case he got a hole in one! It was a great pun!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Oh, right! Thanks for reminding me. I'm glad you enjoyed it, Joe! Have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "You too, Cathy! Take care!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "I gotta go.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fbf209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
